{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270def65-71ca-4b65-a2dc-bfbd78dccbd9",
   "metadata": {},
   "source": [
    "#1. Load Required Libraries\n",
    "\n",
    "We begin by importing all necessary Python libraries for data manipulation, visualization, model building, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fa42d6-f7d8-4fcc-9ea5-3c5ff541a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,roc_curve,confusion_matrix,classification_report\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a9d4b-815f-4257-9164-b22428f4b6f8",
   "metadata": {},
   "source": [
    "#2. Load Dataset\n",
    "\n",
    "We load the dataset using pandas and perform initial data inspection using .info() and .describe() to understand the structure, types, and statistical summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd171d3-6f34-46b9-a8c6-b26aa5e3b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"data/diabetes.csv\"\n",
    "df=pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16a9119-edaf-473d-aae2-5b41e86345a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1cb40dc-6f40-4d33-bc1a-922a2d826890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8fe37-8311-428e-ab34-427a3200a372",
   "metadata": {},
   "source": [
    "#3. Replace Zeroes with Column Means\n",
    "\n",
    "In some datasets (e.g. Pima Indians Diabetes), zeroes in certain features are invalid and treated as missing values. We replace them with the column mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e7402fd-01ac-4d8e-833d-69a4c12d5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_replace=[\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]\n",
    "for col in cols_to_replace:\n",
    "    df[col]=df[col].replace(0,df[col].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cdbe9a-858a-40c5-982e-f25f30a10d88",
   "metadata": {},
   "source": [
    "#4. Prepare Features and Labels\n",
    "\n",
    "We separate the dataset into features (X) and the target/label (y).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b2086c4-8460-4e44-ae44-f90daef5f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"Outcome\",axis=1)\n",
    "y=df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d9d44-6cf7-4d4f-94d5-a9b0edcaa60d",
   "metadata": {},
   "source": [
    "#5. Train-Test Split and Feature Standardization\n",
    "\n",
    "We split the data into training and testing sets using train_test_split, and then standardize the feature values using StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3439694-c4f6-4fed-946a-c12971fab7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51c9bdf3-4769-49c2-91db-4089a64f45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb08c8-65da-4ebb-8de8-4ae4dc7173c4",
   "metadata": {},
   "source": [
    "#6. Define Models\n",
    "\n",
    "We define a dictionary of machine learning models to evaluate. These models can include classifiers like Logistic Regression, Random Forest, Support Vector Machine, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2f5546b-1431-462d-8157-489cd5928a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    \"Logistic Regression\":LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\":RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\":GradientBoostingClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True,random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric=\"logloss\",use_label_encoder=False,random_state=42)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f0a52-0db2-4d03-be6c-dc1ae17e6057",
   "metadata": {},
   "source": [
    "#7. Train, Predict and Evaluate\n",
    "\n",
    "Each model is trained on the training set, predictions are made on the test set, and performance is evaluated using metrics like accuracy, F1-score, and ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "511b2f01-eaf1-4e91-970b-c57095dd95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "best_score = 0\n",
    "best_model = None\n",
    "best_y_test = None\n",
    "best_y_pred = None\n",
    "best_name = \"\"\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get predicted probabilities for ROC-AUC\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    # Save the results for this model\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1-score\": f1,\n",
    "        \"ROC-AUC-Score\": roc\n",
    "    })\n",
    "    \n",
    "    # Update best model if accuracy improved\n",
    "    if acc > best_score:\n",
    "        best_score = acc\n",
    "        best_model = model\n",
    "        best_y_test = y_test\n",
    "        best_y_pred = y_pred\n",
    "        best_name = name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff51ad-12ca-4b3d-9c27-14b89b45ed7d",
   "metadata": {},
   "source": [
    "#8. Plot Confusion Matrix for Best Model\n",
    "\n",
    "We visualize the confusion matrix for the best-performing model to better understand its classification performance (true positives, false positives, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "250e2c42-170c-40ac-ade8-f82e7f422ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(best_y_test, best_y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix - {best_name}\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot to results folder with the model name\n",
    "plt.savefig(f\"results/confusion_matrix_{best_name.lower().replace(' ', '_')}.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a029b-97b6-4cf0-8c24-d7710c5229f5",
   "metadata": {},
   "source": [
    "#9.Model Comparison Table\n",
    "The performance of all models is stored and compared in a DataFrame. This allows for easy comparison based on accuracy, F1-score, and ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "515c5db7-75c5-4b19-89e9-ec6cf81f09d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Comparison:\n",
      "                  Model  Accuracy  F1-score  ROC-AUC-Score\n",
      "4              XGBoost  0.759740  0.647619       0.819259\n",
      "2    Gradient Boosting  0.753247  0.620000       0.830926\n",
      "1        Random Forest  0.740260  0.600000       0.820926\n",
      "3                  SVM  0.740260  0.600000       0.799074\n",
      "0  Logistic Regression  0.701299  0.530612       0.814444\n"
     ]
    }
   ],
   "source": [
    "results_df=pd.DataFrame(results).sort_values(by=\"Accuracy\",ascending=False)\n",
    "print(\"\\n Model Comparison:\\n\",results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20428b51-45c3-47cf-b4f0-02b3415e340d",
   "metadata": {},
   "source": [
    "#10.Plot ROC Curves\n",
    "\n",
    "To compare models visually in terms of classification thresholds, we plot their ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24c91a64-4c8e-46d8-aa9b-db393e00855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for name,model in models.items():\n",
    "    y_proba=model.predict_proba(X_test)[:,1]\n",
    "    fpr,tpr,_=roc_curve(y_test,y_proba)\n",
    "    plt.plot(fpr,tpr,label=f\"{name}(AUC={roc_auc_score(y_test,y_proba):.2f}\")\n",
    "\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-Curves-Model Comparison\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/roc_curves_comparison.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c133ab9-a325-4f5f-9875-29f0b9f8d5d7",
   "metadata": {},
   "source": [
    "#Save Best Model\n",
    "\n",
    "We save the best model to a .pkl file using joblib, so it can be reused later without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51965d64-e1cf-462d-bfb6-38ad4a75e27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model (XGBoost) saved to results/ folder.\n"
     ]
    }
   ],
   "source": [
    "best_model_name=results_df.iloc[0][\"Model\"]\n",
    "best_model=models[best_model_name]\n",
    "joblib.dump(best_model,f\"results/{best_model_name.replace('','_').lower()}_best_model.pkl\")\n",
    "print(f\"\\nBest model ({best_model_name}) saved to results/ folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
